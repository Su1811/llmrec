{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":1872300,"datasetId":1114664,"databundleVersionId":1910335},{"sourceType":"datasetVersion","sourceId":9515296,"datasetId":5668402,"databundleVersionId":9728381}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q sentence_transformers","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:54:31.865779Z","iopub.execute_input":"2024-10-02T01:54:31.866498Z","iopub.status.idle":"2024-10-02T01:54:46.866450Z","shell.execute_reply.started":"2024-10-02T01:54:31.866454Z","shell.execute_reply":"2024-10-02T01:54:46.865151Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict\n\nimport gc\nimport os\nimport copy\nimport time\nimport random\nfrom tqdm.auto import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-02T01:54:46.869011Z","iopub.execute_input":"2024-10-02T01:54:46.869810Z","iopub.status.idle":"2024-10-02T01:54:49.850807Z","shell.execute_reply.started":"2024-10-02T01:54:46.869759Z","shell.execute_reply":"2024-10-02T01:54:49.849949Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"tqdm.pandas()\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:54:49.851976Z","iopub.execute_input":"2024-10-02T01:54:49.852345Z","iopub.status.idle":"2024-10-02T01:54:49.918662Z","shell.execute_reply.started":"2024-10-02T01:54:49.852314Z","shell.execute_reply":"2024-10-02T01:54:49.917673Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"def fix_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:54:49.921502Z","iopub.execute_input":"2024-10-02T01:54:49.921886Z","iopub.status.idle":"2024-10-02T01:54:49.929102Z","shell.execute_reply.started":"2024-10-02T01:54:49.921843Z","shell.execute_reply":"2024-10-02T01:54:49.928242Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparams","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 2048\nEPOCHS = 20\nLR = [0.0001, 0.0005, 0.001]\n# LR = [0.001]\nDROPOUT_RATE = [0.1, 0.3, 0.5]\nSEEDS = [42]\nTOP_K = 10\nEARLY_STOP = 5\nN_NEG_TRAIN = 100\nN_NEG_TEST = 1000","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:54:49.930209Z","iopub.execute_input":"2024-10-02T01:54:49.930577Z","iopub.status.idle":"2024-10-02T01:54:49.938618Z","shell.execute_reply.started":"2024-10-02T01:54:49.930533Z","shell.execute_reply":"2024-10-02T01:54:49.937883Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"DEFAULT_USER_COL = 'user_id'\nDEFAULT_ITEM_COL = 'movie_id'\nDEFAULT_RATING_COL = 'rating'","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:54:49.939821Z","iopub.execute_input":"2024-10-02T01:54:49.940116Z","iopub.status.idle":"2024-10-02T01:54:49.949012Z","shell.execute_reply.started":"2024-10-02T01:54:49.940072Z","shell.execute_reply":"2024-10-02T01:54:49.948074Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def _read_users(data_path):\n    columns = ['user_id', 'gender', 'age', 'occupation', 'zip-code']\n    users = pd.read_table(f'{data_path}/users.dat', names = columns, sep = \"::\", encoding = \"latin1\", engine='python')\n    return users\n\n\ndef _read_ratings(data_path):\n    columns = ['user_id', 'movie_id', 'rating', 'timestamp']\n    ratings = pd.read_table(f'{data_path}/ratings.dat', names = columns, sep = \"::\", encoding = \"latin1\", engine='python')\n    return ratings\n\n\ndef _read_movies(data_path):\n    movies = pd.read_csv(data_path)\n    return movies\n\n# Read datasets\ndata_path = '/kaggle/input/movielens-1m-dataset'\nusers = _read_users(data_path)\nratings = _read_ratings(data_path)\n\nmovie_path = '/kaggle/input/movielens-1m-generated-descriptions/original_temp0.csv'\nmovies = _read_movies(movie_path)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:54:49.950091Z","iopub.execute_input":"2024-10-02T01:54:49.950362Z","iopub.status.idle":"2024-10-02T01:54:58.089952Z","shell.execute_reply.started":"2024-10-02T01:54:49.950331Z","shell.execute_reply":"2024-10-02T01:54:58.089104Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"movies = movies[['movie_id', 'genre', 'description']]\nmovies","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:54:58.091161Z","iopub.execute_input":"2024-10-02T01:54:58.091519Z","iopub.status.idle":"2024-10-02T01:54:58.115103Z","shell.execute_reply.started":"2024-10-02T01:54:58.091482Z","shell.execute_reply":"2024-10-02T01:54:58.114069Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"      movie_id                         genre  \\\n0            1   Animation|Children's|Comedy   \n1            2  Adventure|Children's|Fantasy   \n2            3                Comedy|Romance   \n3            4                  Comedy|Drama   \n4            5                        Comedy   \n...        ...                           ...   \n3878      3948                        Comedy   \n3879      3949                         Drama   \n3880      3950                         Drama   \n3881      3951                         Drama   \n3882      3952                Drama|Thriller   \n\n                                            description  \n0     A group of toys embark on an adventure to retu...  \n1     Two siblings discover a magical board game tha...  \n2     Two elderly neighbors, Max and John, continue ...  \n3     Four close-knit friends navigate the complexit...  \n4     A father grapples with his daughter's second w...  \n...                                                 ...  \n3878  A nurse's fiancé faces a series of awkward and...  \n3879  Four individuals' lives spiral into addiction ...  \n3880  A group of young soldiers undergo intense trai...  \n3881  A dysfunctional family living in a two-family ...  \n3882  A female senator faces political and personal ...  \n\n[3883 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_id</th>\n      <th>genre</th>\n      <th>description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Animation|Children's|Comedy</td>\n      <td>A group of toys embark on an adventure to retu...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Adventure|Children's|Fantasy</td>\n      <td>Two siblings discover a magical board game tha...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Comedy|Romance</td>\n      <td>Two elderly neighbors, Max and John, continue ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Comedy|Drama</td>\n      <td>Four close-knit friends navigate the complexit...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Comedy</td>\n      <td>A father grapples with his daughter's second w...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3878</th>\n      <td>3948</td>\n      <td>Comedy</td>\n      <td>A nurse's fiancé faces a series of awkward and...</td>\n    </tr>\n    <tr>\n      <th>3879</th>\n      <td>3949</td>\n      <td>Drama</td>\n      <td>Four individuals' lives spiral into addiction ...</td>\n    </tr>\n    <tr>\n      <th>3880</th>\n      <td>3950</td>\n      <td>Drama</td>\n      <td>A group of young soldiers undergo intense trai...</td>\n    </tr>\n    <tr>\n      <th>3881</th>\n      <td>3951</td>\n      <td>Drama</td>\n      <td>A dysfunctional family living in a two-family ...</td>\n    </tr>\n    <tr>\n      <th>3882</th>\n      <td>3952</td>\n      <td>Drama|Thriller</td>\n      <td>A female senator faces political and personal ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3883 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.merge(pd.merge(ratings, users), movies)\ndf = df[['user_id', 'movie_id', 'rating', 'description']]\ndf['rating'] = [1.0 if r > 0 else 0.0 for r in df['rating']]\ndf","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:54:58.116276Z","iopub.execute_input":"2024-10-02T01:54:58.116607Z","iopub.status.idle":"2024-10-02T01:54:58.795338Z","shell.execute_reply.started":"2024-10-02T01:54:58.116573Z","shell.execute_reply":"2024-10-02T01:54:58.794459Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"         user_id  movie_id  rating  \\\n0              1      1193     1.0   \n1              1       661     1.0   \n2              1       914     1.0   \n3              1      3408     1.0   \n4              1      2355     1.0   \n...          ...       ...     ...   \n1000204     6040      1091     1.0   \n1000205     6040      1094     1.0   \n1000206     6040       562     1.0   \n1000207     6040      1096     1.0   \n1000208     6040      1097     1.0   \n\n                                               description  \n0        A rebellious inmate challenges the oppressive ...  \n1        An orphaned boy embarks on an extraordinary ad...  \n2        A renowned phonetics professor transforms a Co...  \n3        A determined legal clerk uncovers a corporate ...  \n4        A misfit ant teams up with a group of circus b...  \n...                                                    ...  \n1000204  Two insurance salesmen try to cover up the dea...  \n1000205  An IRA member falls in love with the girlfrien...  \n1000206  A socially awkward and bullied seventh-grader ...  \n1000207  A Polish woman is forced to make an impossible...  \n1000208  A lonely boy befriends an extraterrestrial who...  \n\n[1000209 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>movie_id</th>\n      <th>rating</th>\n      <th>description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1193</td>\n      <td>1.0</td>\n      <td>A rebellious inmate challenges the oppressive ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>661</td>\n      <td>1.0</td>\n      <td>An orphaned boy embarks on an extraordinary ad...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>914</td>\n      <td>1.0</td>\n      <td>A renowned phonetics professor transforms a Co...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>3408</td>\n      <td>1.0</td>\n      <td>A determined legal clerk uncovers a corporate ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2355</td>\n      <td>1.0</td>\n      <td>A misfit ant teams up with a group of circus b...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1000204</th>\n      <td>6040</td>\n      <td>1091</td>\n      <td>1.0</td>\n      <td>Two insurance salesmen try to cover up the dea...</td>\n    </tr>\n    <tr>\n      <th>1000205</th>\n      <td>6040</td>\n      <td>1094</td>\n      <td>1.0</td>\n      <td>An IRA member falls in love with the girlfrien...</td>\n    </tr>\n    <tr>\n      <th>1000206</th>\n      <td>6040</td>\n      <td>562</td>\n      <td>1.0</td>\n      <td>A socially awkward and bullied seventh-grader ...</td>\n    </tr>\n    <tr>\n      <th>1000207</th>\n      <td>6040</td>\n      <td>1096</td>\n      <td>1.0</td>\n      <td>A Polish woman is forced to make an impossible...</td>\n    </tr>\n    <tr>\n      <th>1000208</th>\n      <td>6040</td>\n      <td>1097</td>\n      <td>1.0</td>\n      <td>A lonely boy befriends an extraterrestrial who...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000209 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"min(df['user_id']), max(df['user_id'])","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:54:58.799748Z","iopub.execute_input":"2024-10-02T01:54:58.800063Z","iopub.status.idle":"2024-10-02T01:54:59.072489Z","shell.execute_reply.started":"2024-10-02T01:54:58.800030Z","shell.execute_reply":"2024-10-02T01:54:59.071496Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(1, 6040)"},"metadata":{}}]},{"cell_type":"code","source":"user_id_to_index = {user_id:idx for idx, user_id in enumerate(df['user_id'].unique())}","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:54:59.073827Z","iopub.execute_input":"2024-10-02T01:54:59.074197Z","iopub.status.idle":"2024-10-02T01:54:59.089526Z","shell.execute_reply.started":"2024-10-02T01:54:59.074163Z","shell.execute_reply":"2024-10-02T01:54:59.088599Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class NegativeSampler:\n    \"\"\"NegativeSampler class for NCF. Samples a subset of negative items from a given population of items.\"\"\"\n\n    def __init__(\n        self,\n        user,\n        n_samples,\n        seed,\n        user_positive_item_pool,\n        item_pool,\n        print_warnings=True,\n        training=True,\n    ):\n        \"\"\"Constructor\n\n        Args:\n            user (str or int): User to be sampled for.\n            n_samples (int): Number of required samples.\n            user_positive_item_pool (set): Set of items with which user has previously interacted.\n            item_pool (set): Set of all items in population.\n            print_warnings (bool): If true, prints warnings if sampling without replacement and\n                there are not enough items to sample from to satisfy n_neg or n_neg_test.\n            training (bool): Set to true if sampling for the training set or false if for the test set.\n        \"\"\"\n        self.user = user\n        self.n_samples = n_samples\n        self.seed = seed\n        self.user_positive_item_pool = user_positive_item_pool\n        self.item_pool = item_pool\n\n        self.print_warnings = print_warnings\n        self.training = training\n\n        self.user_negative_item_pool = self._get_user_negatives_pool()\n        self.population_size = len(self.user_negative_item_pool)\n        self._check_sample_size()\n#         self._sample = self._sample_negatives()\n\n    def sample(self):\n        \"\"\"Method for sampling uniformly from a population of negative items\n\n        Returns: list\n        \"\"\"\n        return self._sample_negatives()\n\n    def _get_user_negatives_pool(self):\n        # Get list of items user has not interacted with\n        return list(set(self.item_pool) - self.user_positive_item_pool)\n\n    def _sample_negatives(self):\n        random.seed(self.seed)\n        return random.sample(self.user_negative_item_pool, k=self.n_samples)\n\n    def _check_sample_size(self):\n        # If sampling without replacement, check sample population is sufficient and reduce n_samples if not.\n        n_neg_var = \"n_neg\" if self.training else \"n_neg_test\"\n        dataset_name = \"training\" if self.training else \"test\"\n\n        k = min(self.n_samples, self.population_size)\n        if k < self.n_samples and self.print_warnings:\n            warning_string = (\n                \"The population of negative items to sample from is too small for user {}. \"\n                \"Samples needed = {}, negative items = {}. \"\n                \"Reducing samples to {} for this user.\"\n                \"If an equal number of negative samples for each user is required in the {} set, sample with replacement or reduce {}. \"\n                \"This warning can be turned off by setting print_warnings=False\".format(\n                    self.user,\n                    self.n_samples,\n                    self.population_size,\n                    self.population_size,\n                    dataset_name,\n                    n_neg_var,\n                )\n            )\n            logging.warning(warning_string)\n        self.n_samples = k","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:54:59.091130Z","iopub.execute_input":"2024-10-02T01:54:59.091488Z","iopub.status.idle":"2024-10-02T01:54:59.103375Z","shell.execute_reply.started":"2024-10-02T01:54:59.091451Z","shell.execute_reply":"2024-10-02T01:54:59.102427Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    \n    def __init__(\n        self,\n        target_df,\n        user_positive_item_pool,\n        n_neg=1000,\n        seed=42,\n        user_item_dict=None,\n        all_items=None,\n        col_user=DEFAULT_USER_COL,\n        col_item=DEFAULT_ITEM_COL,\n        col_rating=DEFAULT_RATING_COL,\n        train=True,\n        print_warnings=False,\n    ):\n        \"\"\"Constructor\n\n        Args:\n            df (Dataframe): Dataframe\n            col_user (str): User column name.\n            col_item (str): Item column name.\n            col_rating (str): Rating column name.\n            user_positive_item_pool (dict)\n            user_item_dict (dict)\n            all_items (list)\n            n_neg (int): Number of negative samples per positive example for data subset.\n            seed (int): Seed.\n            train(bool): Type of dataset (train/test)\n            print_warnings (bool): If true, prints warnings if sampling without replacement and\n                there are not enough items to sample from to satisfy n_neg or n_neg_test.\n        \"\"\"\n        \n        super(CustomDataset, self).__init__()\n        self.target_df = target_df\n        self.n_neg = n_neg\n        self.seed = seed\n        \n        self.col_user = col_user\n        self.col_item = col_item\n        self.col_rating = col_rating\n        \n        self.user_positive_item_pool = user_positive_item_pool\n        self.user_item_dict = user_item_dict\n        self.all_items = all_items\n        self.train = train\n        self.print_warnings = print_warnings\n        self.users, self.items, self.ratings = self._negative_sampling()\n        \n    \n    def __len__(self) -> int:\n        '''\n        get lenght of data\n        :return: len(data)\n        '''\n        return self.target_df.shape[0]\n\n\n    def __getitem__(self, index):\n        '''\n        transform userId[index], item[inedx] to Tensor.\n        and return to Datalaoder object.\n        :param index: idex for dataset.\n        :return: user,item,rating\n        '''\n        return self.users[index], self.items[index], self.ratings[index]\n\n\n    def _negative_sampling(self):\n    \n        users, items, ratings = [], [], []\n        \n        if self.train:\n            for user in tqdm(self.user_item_dict.keys()):\n                sampler = NegativeSampler(\n                    user,\n                    self.n_neg,\n                    self.seed,\n                    self.user_positive_item_pool.get(user),\n                    self.all_items,\n                    self.print_warnings,\n                    training=self.train,\n                )\n                negative_examples = sampler.sample()\n                self.user_positive_item_pool[user].update(negative_examples)\n                \n                for item in self.user_item_dict.get(user):\n                    users.append(user)\n                    items.append(item)\n                    ratings.append(1.0)\n\n                for neg_example in negative_examples:\n                    users.append(user)\n                    items.append(neg_example)\n                    ratings.append(0.0)\n        else:\n            for idx, row in tqdm(self.target_df.iterrows(), total=self.target_df.shape[0]):\n                user, item = row[self.col_user], row[self.col_item]\n                sampler = NegativeSampler(\n                    user,\n                    self.n_neg,\n                    self.seed,\n                    self.user_positive_item_pool.get(user),\n                    self.all_items,\n                    self.print_warnings,\n                    training=self.train,\n                )\n                negative_examples = sampler.sample()\n                self.user_item_dict[user].update(negative_examples)\n                \n                users.append(user)\n                items.append([item] + negative_examples)\n                ratings.append([1.0] + [0.0] * len(negative_examples))\n    \n        return torch.tensor(users), torch.tensor(items), torch.tensor(ratings)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:54:59.104984Z","iopub.execute_input":"2024-10-02T01:54:59.105240Z","iopub.status.idle":"2024-10-02T01:54:59.122149Z","shell.execute_reply.started":"2024-10-02T01:54:59.105211Z","shell.execute_reply":"2024-10-02T01:54:59.121340Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def get_user_item_dict(df):\n    user_item_dict = dict()\n    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n        user_id, interacted_item_id = row[DEFAULT_USER_COL], row[DEFAULT_ITEM_COL]\n        if user_id not in user_item_dict:\n            user_item_dict[user_id] = set()\n        user_item_dict[user_id].add(interacted_item_id)\n        \n    return user_item_dict","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:54:59.123193Z","iopub.execute_input":"2024-10-02T01:54:59.123522Z","iopub.status.idle":"2024-10-02T01:54:59.137272Z","shell.execute_reply.started":"2024-10-02T01:54:59.123488Z","shell.execute_reply":"2024-10-02T01:54:59.136530Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def get_max_interaction_len(pos_pool):\n    maxx = -1\n    for key in pos_pool.keys():\n        maxx = max(maxx, len(pos_pool[key]))\n    return maxx","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:54:59.138464Z","iopub.execute_input":"2024-10-02T01:54:59.138758Z","iopub.status.idle":"2024-10-02T01:54:59.151311Z","shell.execute_reply.started":"2024-10-02T01:54:59.138726Z","shell.execute_reply":"2024-10-02T01:54:59.150425Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def train_val_test_split(df, train_ratio, val_test_ratio, seed):\n    train_df, test_df = train_test_split(df, train_size=train_ratio, random_state=seed, shuffle=True)\n    val_df, test_df = train_test_split(test_df, test_size=val_test_ratio, random_state=seed, shuffle=True)\n    print(f'Split data with seed {seed} done!')\n    \n    return train_df, val_df, test_df","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:54:59.152602Z","iopub.execute_input":"2024-10-02T01:54:59.153025Z","iopub.status.idle":"2024-10-02T01:54:59.161285Z","shell.execute_reply.started":"2024-10-02T01:54:59.152965Z","shell.execute_reply":"2024-10-02T01:54:59.160504Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def create_user_item_dict(train_df, val_df, test_df):\n    train_positive_pool = get_user_item_dict(train_df)\n    val_positive_pool = get_user_item_dict(val_df)\n    test_positive_pool = get_user_item_dict(test_df)\n    print(f'Create item pools done!')\n    \n    return train_positive_pool, val_positive_pool, test_positive_pool","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:54:59.162374Z","iopub.execute_input":"2024-10-02T01:54:59.162719Z","iopub.status.idle":"2024-10-02T01:54:59.170363Z","shell.execute_reply.started":"2024-10-02T01:54:59.162679Z","shell.execute_reply":"2024-10-02T01:54:59.169516Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def data_preparing(train_df, val_df, test_df, train_positive_pool, val_positive_pool, test_positive_pool, seed, n_neg_train, n_neg_test):\n    train_dataset = CustomDataset(\n        target_df=train_df,\n        user_positive_item_pool=train_positive_pool,\n        n_neg=n_neg_train,\n        seed=seed, \n        user_item_dict=train_positive_pool,\n        all_items=df[DEFAULT_ITEM_COL].unique(),\n        train=True,\n    )\n    print(f'Create training dataset done!')\n    \n    merged_pos_pool = {\n        key: train_positive_pool.get(key, set()) | val_positive_pool.get(key, set()) for key in set(train_positive_pool) | set(val_positive_pool)\n    }\n    merged_pos_pool = {\n        key: merged_pos_pool.get(key, set()) | test_positive_pool.get(key, set()) for key in set(merged_pos_pool) | set(test_positive_pool)\n    }\n    print(f'Create new positive pool for test/validation done!')\n    \n    val_dataset = CustomDataset(\n        target_df=val_df,\n        user_positive_item_pool=merged_pos_pool,\n        n_neg=n_neg_test,\n        seed=seed,\n        user_item_dict=val_positive_pool,\n        all_items=df[DEFAULT_ITEM_COL].unique(),\n        train=False,\n    )\n    print(f'Create validation dataset done!')\n\n    test_dataset = CustomDataset(\n        target_df=test_df,\n        user_positive_item_pool=merged_pos_pool,\n        n_neg=n_neg_test,\n        seed=seed,\n        user_item_dict=test_positive_pool,\n        all_items=df[DEFAULT_ITEM_COL].unique(),\n        train=False,\n    )\n    print(f'Create testing dataset done!')\n    \n    return train_dataset, val_dataset, test_dataset, val_positive_pool, test_positive_pool","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:54:59.171346Z","iopub.execute_input":"2024-10-02T01:54:59.171631Z","iopub.status.idle":"2024-10-02T01:54:59.181339Z","shell.execute_reply.started":"2024-10-02T01:54:59.171601Z","shell.execute_reply":"2024-10-02T01:54:59.180606Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def data_loader(train_dataset, val_dataset, test_dataset):\n    train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    val_dataloader = DataLoader(dataset=val_dataset, 0shuffle=False)\n    test_dataloader = DataLoader(dataset=test_dataset, shuffle=False)\n    \n    return train_dataloader, val_dataloader, test_dataloader","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:54:59.182406Z","iopub.execute_input":"2024-10-02T01:54:59.182697Z","iopub.status.idle":"2024-10-02T01:54:59.194988Z","shell.execute_reply.started":"2024-10-02T01:54:59.182667Z","shell.execute_reply":"2024-10-02T01:54:59.193941Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Tokenizer","metadata":{}},{"cell_type":"code","source":"import sentence_transformers\nfrom sentence_transformers import SentenceTransformer\n\nitem_embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:54:59.195995Z","iopub.execute_input":"2024-10-02T01:54:59.196329Z","iopub.status.idle":"2024-10-02T01:55:20.984584Z","shell.execute_reply.started":"2024-10-02T01:54:59.196289Z","shell.execute_reply":"2024-10-02T01:55:20.983751Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fda8a86ee09464fa129c6b620c9c7a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e58b8672626407c872f6febe94c469b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09f6f63686fa470fb697b6b33d684691"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4921782660747aba329460a8e4c55c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c19afc4209044c4b8afb14a21ad95178"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bea192de969452dbdaa3d8cfb43d2f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63431bef85f34385a96a1d71ec0a942a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"155466aa6fb84e46a49e9b0ee0b7da76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5d945be0a314bd3996ddb88c945ef05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f96e5104d44a457d98c1c77622ee0342"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fc8821f3ccc41d48175e337126b29e9"}},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 32\nitem_dict = dict()\nidx = 0\n\nwhile idx in range(movies.shape[0]):\n    if idx + batch_size < movies.shape[0]:\n        end_idx = idx + batch_size - 1\n    else:\n        end_idx = movies.shape[0] - 1\n\n    batch_item_des = movies.loc[idx:end_idx, 'description'].tolist()    \n    list_emb = item_embedder.encode(batch_item_des)\n    for i in range(len(list_emb)):\n        item_dict[(movies.loc[idx+i, 'movie_id'])] = list_emb[i]\n    idx = idx + batch_size","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:55:20.985711Z","iopub.execute_input":"2024-10-02T01:55:20.986334Z","iopub.status.idle":"2024-10-02T01:55:27.273796Z","shell.execute_reply.started":"2024-10-02T01:55:20.986299Z","shell.execute_reply":"2024-10-02T01:55:27.272706Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fee4ecd62b64c4e8b1a4203bcb7e3a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7db45a61b0d24652a8c43df384abf813"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9f2e38c551c4eb3820d78721be06146"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3df8754df0f342a28c44b08b19c3ff1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5db51c9867cd473596809e15d4c6f3c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c17190c28ab548ddba36edc8d41e00b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca60ab9ba4974309a23de6bb3a5dfd31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"539160773c1640cf8ccfb4a2905243ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17e7c46a11184e66be949d6edc222e11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ef16ac1090b436290dbe02f71356854"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80f3f7f1bd2446869787f89806b7e3f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16f48680cacf4ff8a3988dbdbc0a2650"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34f3754e5f644f8ba4304a6c57270aff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bd5822803da4ba5b47a589fcae13637"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b9d158abe2c4948b6df3595cf6e7f6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ce84c3584a04f54a3020a1cbe101b19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d940c048a1384624a420305efd8350ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43552a4de877411db9309320d459c250"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc17b84a619043258fe79c49713f5765"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"121b1f6bb2f74ed6831d3e8064d99e3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"139d2801ac724bd1b75aab1d6861d2f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21e2c5e62ceb4fbaa1e7cb9d35b78baf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fd319c5c95f41f3b374fede44723b19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35d544358cf54ea58f5ed9196cf2e7e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d580fd4198104c459956d63c0e39a07c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d305542abd24904b5c2e8de68ed399f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1de4ae4496ac4d1b9280026979e43034"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60ffb47242fb4bfd9385082d335a4af6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cf84cbd6c7a48e39e2a699e761f6334"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9617caac00d469297132ddb846cbf32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5b55c30adf64648a2287f39eb6874c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55be6067aae64ea1bd5a5535dbd7b492"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fca46f64687544628929d32f2f54e433"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe4c5562dd8d4286937e249c040d3038"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f7153ac191c4ddeabb5460d202666e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82954f21eff84da6a5a5599eed62d59e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2ce6094f5a445b5a7f1acda31d05bf6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16dcffa8487d4e2abc27033981dd5404"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a54a22ec0a944709dbe9422f1e311d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b3ae209feff49f68474b0b01c553596"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c63e2dafc414442b8bce0055b5ef5b6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2ff613bdbaa47519bcea2ecf38267c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a08b8a81b8d24586bfcb83dc1b985bb2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fd9cdbcd6ee4923899a52b69abebcca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fec65fb2125499688e24f7771aecbd5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9551a8fa52e4b27a567b0a2d3f9927b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a182c83d7a942adbb65190319fb7175"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c7d9b8ab5c64280a0242cf4b018d773"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3297719ace0b44898dea2ee4a3d29a47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a281dacb8604057a5cc63c7967d98c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bff9c4bdd12b4fd1af59217808da19b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dbb9f4e271b4f138ff86a6ed308d4fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6474e1ed6dcd41058ee3d9c275d08ba2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdef500a48f24250a849402409ef84d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"528cd465532445c2adcfeb7df119c2ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7643a2de562499495eefee408781061"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f87765a1e12444e98a0b6a1f984fe50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa81af456a4f41bd9396bf387dc2b3c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"716498e5ee564d46855ac83996319e0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db3b20f6d05a47ceaa389bb24da8d8e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3293060ad095492a82a72f5158cdb851"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20e3d658d8f7460099d6a0a8db80fc74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad78c53f4ec24f51a9ab03c1c937b6f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4576d06f45e465288d2716fd56d6590"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf5c1852ea374f0b81e1e8e62480976e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a967c75fad3e43be881182e343c2e7a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"480c2a634f2a4787b84e365d7e148a2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d21e908b3474292a906a10398ad5c93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adba82ca713d4ed4b5d4183c2230ee81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd988b6b33534317a7fa10df62a08d8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ccf350bd9ac4d19ace25979faf777c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de80b581c73a4b23adf2f5961d4ddefb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f39f6c26fc14eb8ab83f530013acdd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b5aa4683375405cacb0d76c6b9a3a39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6bcee69534e4fd69566bacfa9661620"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81aee20b56e9436bb4948bc8debafac5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f848f17afb04afcb39a3938a8612acb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8e2e05b3873467486d4aab3dfd1a996"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43f23a385458448ea40d695ac671e879"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14eda547f03a43f3bc415840c652d4b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfc9cbb102f243fbbc5accb06d056441"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73a464dc73674aa18dd69bb3e5abc046"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0ca4c3dca1042ada2dceaf85fb99c13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19bd938652d149e9a10f69de2adb592e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e063ce4c5cf4954b2cc2cf12e48eec2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bd4a16fec914406bbff0c0dd32fb423"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efe5f09273174128a4a628738c08f7e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9080a65a8cc846a9b4546d69c74a8a16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d84d9449bac41cd8f7169dd40800b4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0e4113e0b46463a89d2cbe9a7389b90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"072a2e55045549d88e2728431963ffdb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"674f4371e1474f59b8f52d63fd6c5daa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52742b168724401fb3c4bed13ab07e41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e1ea728b07e462b8e8d65f5d3aa1d48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d25b89e2ec624d769a3fc94cfb1d4169"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1db5a411d02b4bcaab80415c38053693"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e62dae7a013b4ad792c9f876cf16206e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48103a1c06a94609824943aff71b3d79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54964010e43247a89e11e5a76e8337bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f051a1f375f46aca9c957a92dc3f50a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"133dd33eb4a54511853191a42022e88a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3e46f63916f4f958fc829348c9dd8eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"153e2485c823495e9902ae05241f0948"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5194bd359634140911145e291421cca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75cd49e653d94dcfb1db70711d213ac5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac2a66d5b4a84f4494dc8ad0a71499de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d959efd3281423ea7385e9b27ce67b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28a52404260648f49ca3f964f823e1c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6766333890f44805a693a6adcc72d8fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac98f7567b7f491b99eb9a9b06a01fb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6eca8b6eaeb442ba94ed738bf82c71be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8e1cd91b37d4ca995feff085ab5504b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4967c650b70d447aab41046bc40b185a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f283876167c4052a7ad33abef9fbc9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c6ea81cf64e49e39c1d9cd0aa91f57a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"651fe8a797d74a63bf78b4f0b21dc233"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd87fec6efff40a39f79da6ab4dc80e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fe8f0dc442a4caa9665e0db3604df18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9b829f1a31b41b6936a4ee4f23d83c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c946be99f1c74c9a9345f3f9e50a4200"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a7629f5441e45a6a50a38440ab17734"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f7bc3f049154757bcc2152aabde61d0"}},"metadata":{}}]},{"cell_type":"code","source":"np.asarray(item_dict[1]).shape","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:55:27.275030Z","iopub.execute_input":"2024-10-02T01:55:27.275342Z","iopub.status.idle":"2024-10-02T01:55:27.281785Z","shell.execute_reply.started":"2024-10-02T01:55:27.275309Z","shell.execute_reply":"2024-10-02T01:55:27.280745Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(384,)"},"metadata":{}}]},{"cell_type":"markdown","source":"# MLP","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self,\n                 num_users:int,\n                 item_emb_dim=384,\n                 h_dim=128,\n                 dropout_rate=0.3,\n                 ):\n        super(MLP,self).__init__()\n\n        self.num_users = num_users\n        self.user_embedding = nn.Embedding(num_users, h_dim)\n        self.linear1 = nn.Linear(h_dim, h_dim // 2)\n        \n        self.linear2 = nn.Linear(item_emb_dim, h_dim * 2)\n        self.linear3 = nn.Linear(h_dim * 2, h_dim)\n        self.linear4 = nn.Linear(h_dim, h_dim // 2)\n        self.act1 = nn.ReLU()\n        self.act2 = nn.ReLU()\n        self.act3 = nn.ReLU()\n        self.dropout1 = nn.Dropout(dropout_rate)\n        self.dropout2 = nn.Dropout(dropout_rate)\n\n#         self._init_weight()\n\n#     def _init_weight(self):\n#         nn.init.normal_(self.user_embedding.weight,std=1e-2)\n#         nn.init.xavier_uniform_(self.linear.weight)\n\n        \n    def forward(self, user_ids, item_ids):\n        user_embeddings = self.user_embedding(user_ids)\n        user_embeddings = self.linear1(user_embeddings)\n        user_embeddings = self.act1(user_embeddings)\n        \n        items = item_ids.detach().cpu().tolist()\n        item_embeddings = [item_dict.get(item_id) for item_id in items]\n        item_embeddings = torch.stack([torch.tensor(emb) for emb in item_embeddings]).to(device)\n        item_embeddings = self.linear2(item_embeddings)\n        item_embeddings = self.act2(item_embeddings)\n        item_embeddings = self.dropout1(item_embeddings) \n        item_embeddings = self.linear3(item_embeddings)\n        item_embeddings = self.act3(item_embeddings)\n        item_embeddings = self.dropout2(item_embeddings)\n        item_embeddings = self.linear4(item_embeddings)\n        \n        output = torch.sum(user_embeddings * item_embeddings, dim=1)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:55:27.283085Z","iopub.execute_input":"2024-10-02T01:55:27.283511Z","iopub.status.idle":"2024-10-02T01:55:27.296511Z","shell.execute_reply.started":"2024-10-02T01:55:27.283464Z","shell.execute_reply":"2024-10-02T01:55:27.295029Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def hit(gt_item, pred_items):\n    if gt_item in pred_items:\n        return 1\n    return 0\n\n\ndef ndcg(gt_item, pred_items):\n    if gt_item in pred_items:\n        index = pred_items.index(gt_item)\n        return np.reciprocal(np.log2(index+2))\n    return 0","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:55:27.297754Z","iopub.execute_input":"2024-10-02T01:55:27.298049Z","iopub.status.idle":"2024-10-02T01:55:27.311990Z","shell.execute_reply.started":"2024-10-02T01:55:27.298016Z","shell.execute_reply":"2024-10-02T01:55:27.311101Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model, optimizer, train_loader, criterion):\n    model.train()\n    total_loss = 0\n    total = len(train_loader)\n    \n    progress_bar = tqdm(train_loader, desc='Training', leave=False)\n    \n    for batch in progress_bar:\n        user_ids = batch[0].to(device)\n        user_ids = user_ids.detach().cpu().tolist()\n        user_ids = [user_id_to_index.get(user_id) for user_id in user_ids]\n        user_ids = torch.stack([torch.tensor(user_id) for user_id in user_ids]).to(device)\n        \n        item_ids = batch[1].to(device)\n        ratings = batch[2].to(device)\n\n        optimizer.zero_grad()\n        preds = model(user_ids, item_ids)\n        \n        loss = criterion(preds, ratings)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        total += len(ratings)\n            \n    return total_loss / total\n\ndef test(model, test_dataloader, test_positive_pool, top_k):\n    model.eval()\n    total_loss = 0\n    total = len(test_dataloader)\n    HR = []\n    NDCG = []\n        \n    pred_dict = {}    \n    with torch.no_grad():\n        for user, items in test_positive_pool.items():\n            user_ids = [user_id_to_index.get(user)] * len(items)\n            user_ids = torch.tensor(user_ids).to(device)\n            item_ids = list(items)\n            item_ids = torch.tensor(item_ids).to(device)\n            preds = model(user_ids, item_ids)\n            preds = preds.detach().cpu().tolist()\n            items = list(items)\n            pred_dict[user] = {items[idx]: preds[idx] for idx in range(len(items))} \n\n    \n    progress_bar = tqdm(test_dataloader, desc='Validating', leave=False)\n    \n    with torch.no_grad():\n        for user_id, item_ids, ratings in progress_bar:\n            \n            item_ids = torch.flatten(item_ids)\n            gt_item = item_ids[0].item()\n            item_ids = item_ids.detach().cpu().tolist()\n            \n            preds = [pred_dict[user_id.item()].get(item_id) for item_id in item_ids]\n            preds = torch.tensor(preds).to(device)\n            \n            ratings = torch.flatten(ratings)\n            ratings = ratings.to(device)\n            \n            item_ids = torch.tensor(item_ids).to(device)\n\n            _, indices = torch.topk(preds, top_k)\n            recommends = torch.take(\n                    item_ids, indices).tolist()\n\n            HR.append(hit(gt_item, recommends))\n            NDCG.append(ndcg(gt_item, recommends))\n            \n            loss = criterion(preds, ratings)\n            total_loss += loss.item()\n            \n    return total_loss / total, np.mean(HR)/top_k, np.mean(HR), np.mean(NDCG)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:55:27.313128Z","iopub.execute_input":"2024-10-02T01:55:27.313471Z","iopub.status.idle":"2024-10-02T01:55:27.331728Z","shell.execute_reply.started":"2024-10-02T01:55:27.313429Z","shell.execute_reply":"2024-10-02T01:55:27.330904Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def train(model, optimizer, total_epochs, train_dataloader, val_dataloader, val_positive_pool, criterion, top_k, early_stop=5, val_step=5):\n    train_losses, valid_losses = [], []\n    val_max_recall = 0.0\n    num_decreases = 0\n    \n#     try:\n    for epoch in range(total_epochs):\n        train_loss = train_epoch(model, optimizer, train_dataloader, criterion)\n        \n        print('Epoch {}/{}'.format(epoch, total_epochs - 1))\n        print('-' * 10)\n        print('Training Loss: {:.2e}'.format(train_loss))\n        \n        if (epoch + 1) % val_step == 0:\n            valid_loss, val_precision, val_recall, val_ndcg = test(model, val_dataloader, val_positive_pool, top_k)\n\n            if val_recall > val_max_recall:\n                val_max_recall = val_recall\n                num_decreases = 0\n                torch.save(model.state_dict(), '/kaggle/working/best_model.pt')\n            else:\n                if num_decreases > early_stop:\n                    print('Early Stop!')\n                    break\n                else:\n                    num_decreases += 1\n            print('Validate Loss: {:.2e} Precision@{}: {:.8f} Recall@{}: {:.8f} NDCG@{}: {:.8f}'.format(valid_loss, top_k, val_precision, top_k, val_recall, top_k, val_ndcg))\n            train_losses.append(train_loss)\n            valid_losses.append(valid_loss)\n            \n#     except Exception as e:\n#         print(f'Error {e}!')","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:55:27.332952Z","iopub.execute_input":"2024-10-02T01:55:27.333233Z","iopub.status.idle":"2024-10-02T01:55:27.346024Z","shell.execute_reply.started":"2024-10-02T01:55:27.333202Z","shell.execute_reply":"2024-10-02T01:55:27.345166Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Main","metadata":{}},{"cell_type":"code","source":"max_num_users = df[DEFAULT_USER_COL].nunique()\ncriterion = nn.CrossEntropyLoss()\nweight_decay = 0.0005\nn_neg_train = N_NEG_TRAIN\nn_neg_test = N_NEG_TEST\n\nfor seed in SEEDS:\n    print(f'Seed {seed}:')\n    \n    train_df, val_df, test_df = train_val_test_split(df=df, train_ratio=0.8, val_test_ratio=0.5, seed=seed)\n    train_positive_pool, val_positive_pool, test_positive_pool = create_user_item_dict(train_df, val_df, test_df)\n    train_dataset, val_dataset, test_dataset, val_positive_pool, test_positive_pool = data_preparing(\n        train_df, val_df, test_df,  \n        train_positive_pool, val_positive_pool, test_positive_pool, \n        seed, n_neg_train, n_neg_test\n    )\n    train_dataloader, val_dataloader, test_dataloader = data_loader(train_dataset, val_dataset, test_dataset)\n    del train_dataset, val_dataset, test_dataset\n    gc.collect()\n    \n    for lr in LR:\n        print(f'Learning rate: {lr}')\n        model = MLP(num_users=max_num_users, h_dim=128)\n        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n        \n        # If multiple GPUs are available, use DataParallel\n        if torch.cuda.device_count() > 1:\n            print(f\"Using {torch.cuda.device_count()} GPUs!\")\n            model = nn.DataParallel(model)\n\n        model = model.to(device)\n        \n        st = time.time()\n        train(\n            model=model, \n            optimizer=optimizer,\n            total_epochs=EPOCHS,\n            train_dataloader=train_dataloader, \n            val_dataloader=val_dataloader, \n            val_positive_pool=val_positive_pool,\n            criterion=criterion,\n            top_k=TOP_K,\n            early_stop=EARLY_STOP,\n        )\n        print('Training finished, took {:.2f}s'.format(time.time() - st))\n        \n        del model\n        gc.collect()\n        model = MLP(num_users=max_num_users, h_dim=128)\n        model = nn.DataParallel(model)\n        best_model_cp = torch.load('/kaggle/working/best_model.pt')\n        model.load_state_dict(best_model_cp)\n        model.to(device)\n         \n        _, test_precision, test_recall, test_ndcg = test(model, test_dataloader, test_positive_pool, TOP_K)\n        print('Precision@{}: {:.8f}'.format(TOP_K, test_precision))\n        print('Recall@{}: {:.8f}'.format(TOP_K, test_recall))\n        print('NDCG@{}: {:.8f}'.format(TOP_K, test_ndcg))\n        \n        del model\n        gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-10-02T01:55:27.347502Z","iopub.execute_input":"2024-10-02T01:55:27.347884Z","iopub.status.idle":"2024-10-02T02:08:17.810379Z","shell.execute_reply.started":"2024-10-02T01:55:27.347833Z","shell.execute_reply":"2024-10-02T02:08:17.808464Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Seed 42:\nSplit data with seed 42 done!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/800167 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fe2644bc7b84e6a874b17cc4941ea12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100021 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52663e737bec48fabdaf1d6cea20a703"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100021 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"def489c8a70441a9a542e076f897b50c"}},"metadata":{}},{"name":"stdout","text":"Create item pools done!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6040 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9706ddb6cf354caf9fbdc7389a546ed5"}},"metadata":{}},{"name":"stdout","text":"Create training dataset done!\nCreate new positive pool for test/validation done!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100021 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d566ec5e6e5a4a81a1907b02d3cfca39"}},"metadata":{}},{"name":"stdout","text":"Create validation dataset done!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100021 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"998093455e544254ae6225ce8567e446"}},"metadata":{}},{"name":"stdout","text":"Create testing dataset done!\nLearning rate: 0.0001\nUsing 2 GPUs!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd5a31c3e30d4a0cacc263420a5b92b6"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     33\u001b[0m st \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 34\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_positive_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_positive_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTOP_K\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEARLY_STOP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining finished, took \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m st))\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m model\n","Cell \u001b[0;32mIn[26], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, total_epochs, train_dataloader, val_dataloader, val_positive_pool, criterion, top_k, early_stop, val_step)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     try:\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_epochs):\n\u001b[0;32m----> 8\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch, total_epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n","Cell \u001b[0;32mIn[25], line 20\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, train_loader, criterion)\u001b[0m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m preds \u001b[38;5;241m=\u001b[39m model(user_ids, item_ids)\n\u001b[0;32m---> 20\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:1188\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:3104\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3103\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: \"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Float'"],"ename":"RuntimeError","evalue":"\"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Float'","output_type":"error"}]}]}